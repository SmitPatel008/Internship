{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd368a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8869ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd129c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ea5c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rows=[]\n",
    "row_tags=driver.find_elements(By.XPATH,'//div[@class=\"vector-body ve-init-mw-desktopArticleTarget-targetContainer\"]/div[3]/div/table[2]/tbody/tr')\n",
    "for i in row_tags[0:100]:\n",
    "    row=i.text\n",
    "    Rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6c7fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. \"Baby Shark Dance\"[6] Pinkfong Baby Shark - Kids\\' Songs & Stories 13.01 June 17, 2016 [A]',\n",
       " '2. \"Despacito\"[9] Luis Fonsi 8.20 January 12, 2017 [B]',\n",
       " '3. \"Johny Johny Yes Papa\"[16] LooLoo Kids 6.73 October 8, 2016',\n",
       " '4. \"Bath Song\"[17] Cocomelon – Nursery Rhymes 6.26 May 2, 2018',\n",
       " '5. \"Shape of You\"[18] Ed Sheeran 6.02 January 30, 2017 [C]',\n",
       " '6. \"See You Again\"[21] Wiz Khalifa 5.94 April 6, 2015 [D]',\n",
       " '7. \"Phonics Song with Two Words\"[26] ChuChu TV 5.36 March 6, 2014',\n",
       " '8. \"Wheels on the Bus\"[27] Cocomelon – Nursery Rhymes 5.36 May 24, 2018',\n",
       " '9. \"Uptown Funk\"[28] Mark Ronson 4.96 November 19, 2014',\n",
       " '10. \"Learning Colors – Colorful Eggs on a Farm\"[29] Miroshka TV 4.91 February 27, 2018',\n",
       " '11. \"Gangnam Style\"[30] Psy 4.83 July 15, 2012 [E]',\n",
       " '12. \"Masha and the Bear – Recipe for Disaster\"[35] Get Movies 4.55 January 31, 2012',\n",
       " '13. \"Dame Tu Cosita\"[36] El Chombo 4.38 April 5, 2018',\n",
       " '14. \"Axel F\"[37] Crazy Frog 3.95 June 16, 2009',\n",
       " '15. \"Sugar\"[38] Maroon 5 3.89 January 14, 2015',\n",
       " '16. \"Roar\"[39] Katy Perry 3.82 September 5, 2013',\n",
       " '17. \"Counting Stars\"[40] OneRepublic 3.81 May 31, 2013',\n",
       " '18. \"Baa Baa Black Sheep\"[41] Cocomelon – Nursery Rhymes 3.69 June 25, 2018',\n",
       " '19. \"Sorry\"[42] Justin Bieber 3.67 October 22, 2015',\n",
       " '20. \"Waka Waka (This Time for Africa)\"[43] Shakira 3.63 June 4, 2010',\n",
       " '21. \"Thinking Out Loud\"[44] Ed Sheeran 3.61 October 7, 2014',\n",
       " '22. \"Lakdi Ki Kathi\"[45] Jingle Toons 3.56 June 14, 2018',\n",
       " '23. \"Dark Horse\"[46] Katy Perry 3.54 February 20, 2014',\n",
       " '24. \"Perfect\"[47] Ed Sheeran 3.48 November 9, 2017',\n",
       " '25. \"Faded\"[48] Alan Walker 3.47 December 3, 2015',\n",
       " '26. \"Let Her Go\"[49] Passenger 3.46 July 25, 2012',\n",
       " '27. \"Humpty the train on a fruits ride\"[50] Kiddiestv Hindi – Nursery Rhymes & Kids Songs 3.46 January 26, 2018',\n",
       " '28. \"Girls Like You\"[51] Maroon 5 3.43 May 31, 2018',\n",
       " '29. \"Bailando\"[52] Enrique Iglesias 3.41 April 11, 2014',\n",
       " '30. \"Lean On\"[53] Major Lazer 3.40 March 22, 2015']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ec9e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank           Song      Artist Views (billions) Upload Date  \\\n",
      "0     1           Baby       Shark        Dance\"[6]    Pinkfong   \n",
      "1     2  Despacito\"[9]        Luis            Fonsi        8.20   \n",
      "2     3          Johny       Johny              Yes   Papa\"[16]   \n",
      "3     4           Bath   Song\"[17]        Cocomelon           –   \n",
      "4     5          Shape          of         You\"[18]          Ed   \n",
      "5     6            See         You       Again\"[21]         Wiz   \n",
      "6     7        Phonics        Song             with         Two   \n",
      "7     8         Wheels          on              the    Bus\"[27]   \n",
      "8     9         Uptown   Funk\"[28]             Mark      Ronson   \n",
      "9    10       Learning      Colors                –    Colorful   \n",
      "10   11        Gangnam  Style\"[30]              Psy        4.83   \n",
      "11   12          Masha         and              the        Bear   \n",
      "12   13           Dame          Tu      Cosita\"[36]          El   \n",
      "13   14           Axel      F\"[37]            Crazy        Frog   \n",
      "14   15     Sugar\"[38]      Maroon                5        3.89   \n",
      "15   16      Roar\"[39]        Katy            Perry        3.82   \n",
      "16   17       Counting  Stars\"[40]      OneRepublic        3.81   \n",
      "17   18            Baa         Baa            Black  Sheep\"[41]   \n",
      "18   19     Sorry\"[42]      Justin           Bieber        3.67   \n",
      "19   20           Waka        Waka            (This        Time   \n",
      "20   21       Thinking         Out        Loud\"[44]          Ed   \n",
      "21   22          Lakdi          Ki       Kathi\"[45]      Jingle   \n",
      "22   23           Dark  Horse\"[46]             Katy       Perry   \n",
      "23   24   Perfect\"[47]          Ed          Sheeran        3.48   \n",
      "24   25     Faded\"[48]        Alan           Walker        3.47   \n",
      "25   26            Let         Her          Go\"[49]   Passenger   \n",
      "26   27         Humpty         the            train          on   \n",
      "27   28          Girls        Like         You\"[51]      Maroon   \n",
      "28   29  Bailando\"[52]     Enrique         Iglesias        3.41   \n",
      "29   30           Lean     On\"[53]            Major       Lazer   \n",
      "\n",
      "   Additional Info  \n",
      "0             Baby  \n",
      "1          January  \n",
      "2           LooLoo  \n",
      "3          Nursery  \n",
      "4          Sheeran  \n",
      "5          Khalifa  \n",
      "6        Words\"[26  \n",
      "7        Cocomelon  \n",
      "8             4.96  \n",
      "9             Eggs  \n",
      "10            July  \n",
      "11               –  \n",
      "12          Chombo  \n",
      "13            3.95  \n",
      "14         January  \n",
      "15       September  \n",
      "16             May  \n",
      "17       Cocomelon  \n",
      "18         October  \n",
      "19             for  \n",
      "20         Sheeran  \n",
      "21           Toons  \n",
      "22            3.54  \n",
      "23        November  \n",
      "24        December  \n",
      "25            3.46  \n",
      "26               a  \n",
      "27               5  \n",
      "28           April  \n",
      "29            3.40  \n"
     ]
    }
   ],
   "source": [
    "data_dict = {\n",
    "    'Rank': [],\n",
    "    'Song': [],\n",
    "    'Artist': [],\n",
    "    'Views (billions)': [],\n",
    "    'Upload Date': [],\n",
    "    'Additional Info': []\n",
    "}\n",
    "\n",
    "for entry in Rows:\n",
    "    entry_parts = entry.split(' ', maxsplit=6)\n",
    "    rank = entry_parts[0].strip('.')\n",
    "    song_artist = entry_parts[1].strip('\" \"')\n",
    "    song = song_artist\n",
    "    artist = entry_parts[2]\n",
    "    views = entry_parts[3]\n",
    "    upload_date = entry_parts[4]\n",
    "    additional_info = entry_parts[5].strip('[]')\n",
    "\n",
    "    data_dict['Rank'].append(rank)\n",
    "    data_dict['Song'].append(song)\n",
    "    data_dict['Artist'].append(artist)\n",
    "    data_dict['Views (billions)'].append(views)\n",
    "    data_dict['Upload Date'].append(upload_date)\n",
    "    data_dict['Additional Info'].append(additional_info)\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58a6e868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank = []\n",
    "title = []\n",
    "artist = []\n",
    "views = []\n",
    "date = []\n",
    "note = []\n",
    "\n",
    "for row in Rows:\n",
    "    \n",
    "    rank.append(row.split('.')[0].strip())\n",
    "    title.append(row.split('\"')[1])\n",
    "    artist.append(row.split('\"')[2].strip())\n",
    "    views.append(row.split()[-4])\n",
    "    date.append(' '.join(row.split()[-2:]))\n",
    "    note.append(row.split()[-4][1:-1] if row.split()[-4].startswith('[') else '')\n",
    "\n",
    "songs_dict = {\n",
    "    'Rank': rank,\n",
    "    'Title': title,\n",
    "    'Artist': artist,\n",
    "    'Views (billions)': views,\n",
    "    'Publication Date': date,\n",
    "    'Note': note\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(songs_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0709dc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>[6] Pinkfong Baby Shark - Kids' Songs &amp; Storie...</td>\n",
       "      <td>June</td>\n",
       "      <td>2016 [A]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Despacito</td>\n",
       "      <td>[9] Luis Fonsi 8.20 January 12, 2017 [B]</td>\n",
       "      <td>January</td>\n",
       "      <td>2017 [B]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>[16] LooLoo Kids 6.73 October 8, 2016</td>\n",
       "      <td>6.73</td>\n",
       "      <td>8, 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bath Song</td>\n",
       "      <td>[17] Cocomelon – Nursery Rhymes 6.26 May 2, 2018</td>\n",
       "      <td>6.26</td>\n",
       "      <td>2, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>[18] Ed Sheeran 6.02 January 30, 2017 [C]</td>\n",
       "      <td>January</td>\n",
       "      <td>2017 [C]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>See You Again</td>\n",
       "      <td>[21] Wiz Khalifa 5.94 April 6, 2015 [D]</td>\n",
       "      <td>April</td>\n",
       "      <td>2015 [D]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>[26] ChuChu TV 5.36 March 6, 2014</td>\n",
       "      <td>5.36</td>\n",
       "      <td>6, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>[27] Cocomelon – Nursery Rhymes 5.36 May 24, 2018</td>\n",
       "      <td>5.36</td>\n",
       "      <td>24, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>[28] Mark Ronson 4.96 November 19, 2014</td>\n",
       "      <td>4.96</td>\n",
       "      <td>19, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>[29] Miroshka TV 4.91 February 27, 2018</td>\n",
       "      <td>4.91</td>\n",
       "      <td>27, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>[30] Psy 4.83 July 15, 2012 [E]</td>\n",
       "      <td>July</td>\n",
       "      <td>2012 [E]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>[35] Get Movies 4.55 January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "      <td>31, 2012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>[36] El Chombo 4.38 April 5, 2018</td>\n",
       "      <td>4.38</td>\n",
       "      <td>5, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Axel F</td>\n",
       "      <td>[37] Crazy Frog 3.95 June 16, 2009</td>\n",
       "      <td>3.95</td>\n",
       "      <td>16, 2009</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sugar</td>\n",
       "      <td>[38] Maroon 5 3.89 January 14, 2015</td>\n",
       "      <td>3.89</td>\n",
       "      <td>14, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Roar</td>\n",
       "      <td>[39] Katy Perry 3.82 September 5, 2013</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5, 2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>[40] OneRepublic 3.81 May 31, 2013</td>\n",
       "      <td>3.81</td>\n",
       "      <td>31, 2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>[41] Cocomelon – Nursery Rhymes 3.69 June 25, ...</td>\n",
       "      <td>3.69</td>\n",
       "      <td>25, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sorry</td>\n",
       "      <td>[42] Justin Bieber 3.67 October 22, 2015</td>\n",
       "      <td>3.67</td>\n",
       "      <td>22, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>[43] Shakira 3.63 June 4, 2010</td>\n",
       "      <td>3.63</td>\n",
       "      <td>4, 2010</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>[44] Ed Sheeran 3.61 October 7, 2014</td>\n",
       "      <td>3.61</td>\n",
       "      <td>7, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>[45] Jingle Toons 3.56 June 14, 2018</td>\n",
       "      <td>3.56</td>\n",
       "      <td>14, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>[46] Katy Perry 3.54 February 20, 2014</td>\n",
       "      <td>3.54</td>\n",
       "      <td>20, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>[47] Ed Sheeran 3.48 November 9, 2017</td>\n",
       "      <td>3.48</td>\n",
       "      <td>9, 2017</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Faded</td>\n",
       "      <td>[48] Alan Walker 3.47 December 3, 2015</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>[49] Passenger 3.46 July 25, 2012</td>\n",
       "      <td>3.46</td>\n",
       "      <td>25, 2012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>[50] Kiddiestv Hindi – Nursery Rhymes &amp; Kids S...</td>\n",
       "      <td>3.46</td>\n",
       "      <td>26, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>[51] Maroon 5 3.43 May 31, 2018</td>\n",
       "      <td>3.43</td>\n",
       "      <td>31, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bailando</td>\n",
       "      <td>[52] Enrique Iglesias 3.41 April 11, 2014</td>\n",
       "      <td>3.41</td>\n",
       "      <td>11, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lean On</td>\n",
       "      <td>[53] Major Lazer 3.40 March 22, 2015</td>\n",
       "      <td>3.40</td>\n",
       "      <td>22, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "Rank                                              \n",
       "1                              Baby Shark Dance   \n",
       "2                                     Despacito   \n",
       "3                          Johny Johny Yes Papa   \n",
       "4                                     Bath Song   \n",
       "5                                  Shape of You   \n",
       "6                                 See You Again   \n",
       "7                   Phonics Song with Two Words   \n",
       "8                             Wheels on the Bus   \n",
       "9                                   Uptown Funk   \n",
       "10    Learning Colors – Colorful Eggs on a Farm   \n",
       "11                                Gangnam Style   \n",
       "12     Masha and the Bear – Recipe for Disaster   \n",
       "13                               Dame Tu Cosita   \n",
       "14                                       Axel F   \n",
       "15                                        Sugar   \n",
       "16                                         Roar   \n",
       "17                               Counting Stars   \n",
       "18                          Baa Baa Black Sheep   \n",
       "19                                        Sorry   \n",
       "20             Waka Waka (This Time for Africa)   \n",
       "21                            Thinking Out Loud   \n",
       "22                               Lakdi Ki Kathi   \n",
       "23                                   Dark Horse   \n",
       "24                                      Perfect   \n",
       "25                                        Faded   \n",
       "26                                   Let Her Go   \n",
       "27            Humpty the train on a fruits ride   \n",
       "28                               Girls Like You   \n",
       "29                                     Bailando   \n",
       "30                                      Lean On   \n",
       "\n",
       "                                                 Artist Views (billions)  \\\n",
       "Rank                                                                       \n",
       "1     [6] Pinkfong Baby Shark - Kids' Songs & Storie...             June   \n",
       "2              [9] Luis Fonsi 8.20 January 12, 2017 [B]          January   \n",
       "3                 [16] LooLoo Kids 6.73 October 8, 2016             6.73   \n",
       "4      [17] Cocomelon – Nursery Rhymes 6.26 May 2, 2018             6.26   \n",
       "5             [18] Ed Sheeran 6.02 January 30, 2017 [C]          January   \n",
       "6               [21] Wiz Khalifa 5.94 April 6, 2015 [D]            April   \n",
       "7                     [26] ChuChu TV 5.36 March 6, 2014             5.36   \n",
       "8     [27] Cocomelon – Nursery Rhymes 5.36 May 24, 2018             5.36   \n",
       "9               [28] Mark Ronson 4.96 November 19, 2014             4.96   \n",
       "10              [29] Miroshka TV 4.91 February 27, 2018             4.91   \n",
       "11                      [30] Psy 4.83 July 15, 2012 [E]             July   \n",
       "12                [35] Get Movies 4.55 January 31, 2012             4.55   \n",
       "13                    [36] El Chombo 4.38 April 5, 2018             4.38   \n",
       "14                   [37] Crazy Frog 3.95 June 16, 2009             3.95   \n",
       "15                  [38] Maroon 5 3.89 January 14, 2015             3.89   \n",
       "16               [39] Katy Perry 3.82 September 5, 2013             3.82   \n",
       "17                   [40] OneRepublic 3.81 May 31, 2013             3.81   \n",
       "18    [41] Cocomelon – Nursery Rhymes 3.69 June 25, ...             3.69   \n",
       "19             [42] Justin Bieber 3.67 October 22, 2015             3.67   \n",
       "20                       [43] Shakira 3.63 June 4, 2010             3.63   \n",
       "21                 [44] Ed Sheeran 3.61 October 7, 2014             3.61   \n",
       "22                 [45] Jingle Toons 3.56 June 14, 2018             3.56   \n",
       "23               [46] Katy Perry 3.54 February 20, 2014             3.54   \n",
       "24                [47] Ed Sheeran 3.48 November 9, 2017             3.48   \n",
       "25               [48] Alan Walker 3.47 December 3, 2015             3.47   \n",
       "26                    [49] Passenger 3.46 July 25, 2012             3.46   \n",
       "27    [50] Kiddiestv Hindi – Nursery Rhymes & Kids S...             3.46   \n",
       "28                      [51] Maroon 5 3.43 May 31, 2018             3.43   \n",
       "29            [52] Enrique Iglesias 3.41 April 11, 2014             3.41   \n",
       "30                 [53] Major Lazer 3.40 March 22, 2015             3.40   \n",
       "\n",
       "     Publication Date Note  \n",
       "Rank                        \n",
       "1            2016 [A]       \n",
       "2            2017 [B]       \n",
       "3             8, 2016       \n",
       "4             2, 2018       \n",
       "5            2017 [C]       \n",
       "6            2015 [D]       \n",
       "7             6, 2014       \n",
       "8            24, 2018       \n",
       "9            19, 2014       \n",
       "10           27, 2018       \n",
       "11           2012 [E]       \n",
       "12           31, 2012       \n",
       "13            5, 2018       \n",
       "14           16, 2009       \n",
       "15           14, 2015       \n",
       "16            5, 2013       \n",
       "17           31, 2013       \n",
       "18           25, 2018       \n",
       "19           22, 2015       \n",
       "20            4, 2010       \n",
       "21            7, 2014       \n",
       "22           14, 2018       \n",
       "23           20, 2014       \n",
       "24            9, 2017       \n",
       "25            3, 2015       \n",
       "26           25, 2012       \n",
       "27           26, 2018       \n",
       "28           31, 2018       \n",
       "29           11, 2014       \n",
       "30           22, 2015       "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "You_tube_videos_Rank=df.set_index('Rank')\n",
    "You_tube_videos_Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178575f",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8bbabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a68405",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "Search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ae0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div\")\n",
    "Search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1b54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[2]/div[1]/input\")\n",
    "Teams.send_keys('India')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c97f018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teamclick=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[2]/div[3]\")\n",
    "Teamclick.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22fc1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf2c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    Match_title.append(title)\n",
    "Serie_tags=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in Serie_tags[0:10]:\n",
    "    Serie=i.text\n",
    "    Series.append(Serie)\n",
    "PLACE_tags=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in PLACE_tags[0:10]:\n",
    "    PLACE=i.text\n",
    "    Place.append(PLACE)\n",
    "date_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date_tags[0:10]:\n",
    "    date=i.text\n",
    "    Date.append(date)\n",
    "time_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time_tags[0:10]:\n",
    "    time=i.text\n",
    "    Time.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d7f631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Windsor Park,</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Queen's Park Oval,</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval,</td>\n",
       "      <td>27 JUL 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval,</td>\n",
       "      <td>29 JUL 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium,</td>\n",
       "      <td>1 AUG 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium,</td>\n",
       "      <td>3 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium,</td>\n",
       "      <td>6 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium,</td>\n",
       "      <td>8 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                          Series                Place  \\\n",
       "0  1st Test -  INDIA TOUR OF WEST INDIES 2023        Windsor Park,   \n",
       "1  2nd Test -  INDIA TOUR OF WEST INDIES 2023   Queen's Park Oval,   \n",
       "2   1st ODI -  INDIA TOUR OF WEST INDIES 2023     Kensington Oval,   \n",
       "3   2nd ODI -  INDIA TOUR OF WEST INDIES 2023     Kensington Oval,   \n",
       "4   3rd ODI -  INDIA TOUR OF WEST INDIES 2023  Brian Lara Stadium,   \n",
       "5  1st T20I -  INDIA TOUR OF WEST INDIES 2023  Brian Lara Stadium,   \n",
       "6  2nd T20I -  INDIA TOUR OF WEST INDIES 2023    National Stadium,   \n",
       "7  3rd T20I -  INDIA TOUR OF WEST INDIES 2023    National Stadium,   \n",
       "\n",
       "          Date         Time  \n",
       "0  12 JUL 2023  7:30 PM IST  \n",
       "1  20 JUL 2023  7:30 PM IST  \n",
       "2  27 JUL 2023  7:00 PM IST  \n",
       "3  29 JUL 2023  7:00 PM IST  \n",
       "4   1 AUG 2023  7:00 PM IST  \n",
       "5   3 AUG 2023  8:00 PM IST  \n",
       "6   6 AUG 2023  8:00 PM IST  \n",
       "7   8 AUG 2023  8:00 PM IST  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2=pd.DataFrame({'Match Title':Match_title[0:10],'Series':Series[0:10],'Place':Place[0:10],'Date':Date[0:10],'Time':Time[0:10]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7092dcd",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3bc77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.statisticstimes.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a474422",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "Search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a370143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7df84556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Country = driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/button/i') \n",
    "    Country.click()\n",
    "except ElementNotInteractableException: \n",
    "    print(\"The element is not currently interactable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7400a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Countrylink = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]') \n",
    "    Countrylink.click()\n",
    "except ElementNotInteractableException: \n",
    "    print(\"The element is not currently interactable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7270afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpstate=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "gdpstate.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1da689d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rows=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5e4064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_tags=driver.find_elements(By.XPATH,'//tr[@class=\"odd\"]')\n",
    "for i in row_tags[0:10]:\n",
    "    row=i.text\n",
    "    Rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83109f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Maharashtra - 2,632,792 13.94% 399.921 - 2,039,074',\n",
       " '1 Maharashtra - 2,632,792 13.94% 399.921 - 2,039,074',\n",
       " '3 Uttar Pradesh 1,687,818 1,584,764 8.39% 240.726 1,166,817 1,123,982',\n",
       " '5 Karnataka 1,631,977 1,493,127 7.91% 226.806 1,156,039 1,091,077',\n",
       " '7 Rajasthan 1,020,989 942,586 4.99% 143.179 711,627 677,428',\n",
       " '9 Telangana 969,604 861,031 4.56% 130.791 663,258 612,828',\n",
       " '11 Kerala - 781,653 4.14% 118.733 - 559,412',\n",
       " '13 Haryana 831,610 734,163 3.89% 111.519 572,240 531,085',\n",
       " '15 Punjab 574,760 526,376 2.79% 79.957 418,868 397,669',\n",
       " '17 Assam - 315,881 1.67% 47.982 - 234,048',\n",
       " '19 Jharkhand 328,598 297,204 1.57% 45.145 240,036 224,986']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf75b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rows2=[]\n",
    "row2_tags=driver.find_elements(By.XPATH,'//tr[@class=\"even\"]')\n",
    "for i in row2_tags[0:10]:\n",
    "    row2=i.text\n",
    "    Rows2.append(row2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0b8f933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Tamil Nadu 1,845,853 1,630,208 8.63% 247.629 1,312,929 1,215,307',\n",
       " '4 Gujarat - 1,502,899 7.96% 228.290 - 1,186,379',\n",
       " '6 West Bengal 1,253,832 1,089,898 5.77% 165.556 793,223 739,525',\n",
       " '8 Andhra Pradesh 972,782 862,957 4.57% 131.083 672,018 621,301',\n",
       " '10 Madhya Pradesh 906,672 809,592 4.29% 122.977 561,801 522,009',\n",
       " '12 Delhi 856,112 774,870 4.10% 117.703 634,408 590,569',\n",
       " '14 Bihar 611,804 530,363 2.81% 80.562 414,977 375,651',\n",
       " '16 Odisha 521,275 487,805 2.58% 74.098 396,499 376,877',\n",
       " '18 Chhattisgarh 329,180 304,063 1.61% 46.187 243,477 231,182',\n",
       " '20 Uttarakhand - 245,895 1.30% 37.351 - 193,273']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rows2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42c43f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rows3=Rows+Rows2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "262bb4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Maharashtra - 2,632,792 13.94% 399.921 - 2,039,074',\n",
       " '1 Maharashtra - 2,632,792 13.94% 399.921 - 2,039,074',\n",
       " '3 Uttar Pradesh 1,687,818 1,584,764 8.39% 240.726 1,166,817 1,123,982',\n",
       " '5 Karnataka 1,631,977 1,493,127 7.91% 226.806 1,156,039 1,091,077',\n",
       " '7 Rajasthan 1,020,989 942,586 4.99% 143.179 711,627 677,428',\n",
       " '9 Telangana 969,604 861,031 4.56% 130.791 663,258 612,828',\n",
       " '11 Kerala - 781,653 4.14% 118.733 - 559,412',\n",
       " '13 Haryana 831,610 734,163 3.89% 111.519 572,240 531,085',\n",
       " '15 Punjab 574,760 526,376 2.79% 79.957 418,868 397,669',\n",
       " '17 Assam - 315,881 1.67% 47.982 - 234,048',\n",
       " '19 Jharkhand 328,598 297,204 1.57% 45.145 240,036 224,986',\n",
       " '2 Tamil Nadu 1,845,853 1,630,208 8.63% 247.629 1,312,929 1,215,307',\n",
       " '4 Gujarat - 1,502,899 7.96% 228.290 - 1,186,379',\n",
       " '6 West Bengal 1,253,832 1,089,898 5.77% 165.556 793,223 739,525',\n",
       " '8 Andhra Pradesh 972,782 862,957 4.57% 131.083 672,018 621,301',\n",
       " '10 Madhya Pradesh 906,672 809,592 4.29% 122.977 561,801 522,009',\n",
       " '12 Delhi 856,112 774,870 4.10% 117.703 634,408 590,569',\n",
       " '14 Bihar 611,804 530,363 2.81% 80.562 414,977 375,651',\n",
       " '16 Odisha 521,275 487,805 2.58% 74.098 396,499 376,877',\n",
       " '18 Chhattisgarh 329,180 304,063 1.61% 46.187 243,477 231,182',\n",
       " '20 Uttarakhand - 245,895 1.30% 37.351 - 193,273']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rows3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "934c19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_data = {}\n",
    "for item in Rows3:\n",
    "    parts = item.split(' ')\n",
    "    rank = int(parts[0])\n",
    "    rank_data[rank] = item\n",
    "\n",
    "sorted_data = [rank_data[key] for key in sorted(rank_data.keys())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "945a5263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Maharashtra - 2,632,792 13.94% 399.921 - 2,039,074',\n",
       " '2 Tamil Nadu 1,845,853 1,630,208 8.63% 247.629 1,312,929 1,215,307',\n",
       " '3 Uttar Pradesh 1,687,818 1,584,764 8.39% 240.726 1,166,817 1,123,982',\n",
       " '4 Gujarat - 1,502,899 7.96% 228.290 - 1,186,379',\n",
       " '5 Karnataka 1,631,977 1,493,127 7.91% 226.806 1,156,039 1,091,077',\n",
       " '6 West Bengal 1,253,832 1,089,898 5.77% 165.556 793,223 739,525',\n",
       " '7 Rajasthan 1,020,989 942,586 4.99% 143.179 711,627 677,428',\n",
       " '8 Andhra Pradesh 972,782 862,957 4.57% 131.083 672,018 621,301',\n",
       " '9 Telangana 969,604 861,031 4.56% 130.791 663,258 612,828',\n",
       " '10 Madhya Pradesh 906,672 809,592 4.29% 122.977 561,801 522,009',\n",
       " '11 Kerala - 781,653 4.14% 118.733 - 559,412',\n",
       " '12 Delhi 856,112 774,870 4.10% 117.703 634,408 590,569',\n",
       " '13 Haryana 831,610 734,163 3.89% 111.519 572,240 531,085',\n",
       " '14 Bihar 611,804 530,363 2.81% 80.562 414,977 375,651',\n",
       " '15 Punjab 574,760 526,376 2.79% 79.957 418,868 397,669',\n",
       " '16 Odisha 521,275 487,805 2.58% 74.098 396,499 376,877',\n",
       " '17 Assam - 315,881 1.67% 47.982 - 234,048',\n",
       " '18 Chhattisgarh 329,180 304,063 1.61% 46.187 243,477 231,182',\n",
       " '19 Jharkhand 328,598 297,204 1.57% 45.145 240,036 224,986',\n",
       " '20 Uttarakhand - 245,895 1.30% 37.351 - 193,273']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43dbf319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Maharashtra', '-', '2,632,792', '13.94%', '399.921', '-', '2,039,074']\n",
      "['2', 'Tamil', 'Nadu', '1,845,853', '1,630,208', '8.63%', '247.629', '1,312,929', '1,215,307']\n",
      "['3', 'Uttar', 'Pradesh', '1,687,818', '1,584,764', '8.39%', '240.726', '1,166,817', '1,123,982']\n",
      "['4', 'Gujarat', '-', '1,502,899', '7.96%', '228.290', '-', '1,186,379']\n",
      "['5', 'Karnataka', '1,631,977', '1,493,127', '7.91%', '226.806', '1,156,039', '1,091,077']\n",
      "['6', 'West', 'Bengal', '1,253,832', '1,089,898', '5.77%', '165.556', '793,223', '739,525']\n",
      "['7', 'Rajasthan', '1,020,989', '942,586', '4.99%', '143.179', '711,627', '677,428']\n",
      "['8', 'Andhra', 'Pradesh', '972,782', '862,957', '4.57%', '131.083', '672,018', '621,301']\n",
      "['9', 'Telangana', '969,604', '861,031', '4.56%', '130.791', '663,258', '612,828']\n",
      "['10', 'Madhya', 'Pradesh', '906,672', '809,592', '4.29%', '122.977', '561,801', '522,009']\n",
      "['11', 'Kerala', '-', '781,653', '4.14%', '118.733', '-', '559,412']\n",
      "['12', 'Delhi', '856,112', '774,870', '4.10%', '117.703', '634,408', '590,569']\n",
      "['13', 'Haryana', '831,610', '734,163', '3.89%', '111.519', '572,240', '531,085']\n",
      "['14', 'Bihar', '611,804', '530,363', '2.81%', '80.562', '414,977', '375,651']\n",
      "['15', 'Punjab', '574,760', '526,376', '2.79%', '79.957', '418,868', '397,669']\n",
      "['16', 'Odisha', '521,275', '487,805', '2.58%', '74.098', '396,499', '376,877']\n",
      "['17', 'Assam', '-', '315,881', '1.67%', '47.982', '-', '234,048']\n",
      "['18', 'Chhattisgarh', '329,180', '304,063', '1.61%', '46.187', '243,477', '231,182']\n",
      "['19', 'Jharkhand', '328,598', '297,204', '1.57%', '45.145', '240,036', '224,986']\n",
      "['20', 'Uttarakhand', '-', '245,895', '1.30%', '37.351', '-', '193,273']\n"
     ]
    }
   ],
   "source": [
    "for item in sorted_data:\n",
    "    values = item.split(' ')\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d5eedb62",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14044\\1493126926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msplit_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mRank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mColumn1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mColumn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "Rank = []\n",
    "State = []\n",
    "Column1 = []\n",
    "Column2 = []\n",
    "\n",
    "for item in values [0:10]:\n",
    "    split_items = item.split(',')\n",
    "    Rank.append(split_items[0])\n",
    "    State.append(split_items[1])\n",
    "    Column1.append(split_items[2])\n",
    "    Column2.append(split_items[3])\n",
    "\n",
    "print(Rank)\n",
    "print(State)\n",
    "print(Column1)\n",
    "print(Column2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371d996",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df86859",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://github.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc29283",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    drop = driver.find_element(By.XPATH,'//ul[@class=\"d-lg-flex list-style-none\"]/li[3]/button') \n",
    "    drop.click()\n",
    "except ElementNotInteractableException: \n",
    "    print(\"The element is not currently interactable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77de3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Countrylink = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a') \n",
    "    Countrylink.click()\n",
    "except ElementNotInteractableException: \n",
    "    print(\"The element is not currently interactable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e0bdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Description=[]\n",
    "Count=[]\n",
    "Language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63c3ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "for i in title_tags[0:50]:\n",
    "    title=i.text\n",
    "    Title.append(title)\n",
    "desc_tags=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in desc_tags[0:50]:\n",
    "    desc=i.text\n",
    "    Description.append(desc)\n",
    "lan_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article[1]/div[2]/span[1]/span[2]')\n",
    "for i in lan_tags[0:50]:\n",
    "    lan=i.text\n",
    "    Language.append(lan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c5d6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PowerShell for every system!',\n",
       " 'There can be more than Notion and Miro. AFFiNE is a next-gen knowledge base that brings planning, sorting and creating all together. Privacy first, open-source, customizable and ready to use.',\n",
       " 'An open-source C++ library developed and used at Facebook.',\n",
       " 'This is the official code for Faster Segment Anything (MobileSAM) project that makes SAM lightweight for mobile applications and beyond!',\n",
       " 'Remove backgrounds from images directly in the browser environment with ease and no additional costs or privacy concerns. Explore an interactive demo.',\n",
       " 'Curated list of project-based tutorials',\n",
       " '中国大模型',\n",
       " 'All you need for End-to-end Autonomous Driving',\n",
       " 'A list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev',\n",
       " '🥷 Superagent - Build, deploy, and manage LLM-powered agents',\n",
       " 'Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效 ChatGLM 微调',\n",
       " '📚 Freely available programming books',\n",
       " '🧑\\u200d🏫 59 Implementations/tutorials of deep learning papers with side-by-side notes 📝; including transformers (original, xl, switch, feedback, vit, ...), optimizers (adam, adabelief, ...), gans(cyclegan, stylegan2, ...), 🎮 reinforcement learning (ppo, dqn), capsnet, distillation, ... 🧠',\n",
       " '🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.',\n",
       " '🧠 Dump all your files into your private Generative AI Second Brain and chat with it using LLMs ( GPT 3.5/4, Private, Anthropic, VertexAI ) & Embeddings 🧠',\n",
       " 'Cross-platform .NET sample microservices and container based application that runs on Linux Windows and macOS. Powered by .NET 7, Docker Containers and Azure Kubernetes Services. Supports Visual Studio, VS for Mac and CLI based environments with Docker CLI, dotnet CLI, VS Code or any other code editor.',\n",
       " 'Create book from markdown files. Like Gitbook but implemented in Rust',\n",
       " '🆓免费的 ChatGPT 镜像网站列表，持续更新。List of free ChatGPT mirror sites, continuously updated.',\n",
       " 'Ansible for DevOps examples.',\n",
       " '《构筑大语言模型应用：应用开发与架构设计》一本关于 LLM 在真实世界应用的开源电子书，介绍了大语言模型的基础知识和应用，以及如何构建自己的模型。其中包括Prompt的编写、开发和管理，探索最好的大语言模型能带来什么，以及LLM应用开发的模式和架构设计。',\n",
       " 'Chat with your documents on your local device using GPT models. No data leaves your device and 100% private.',\n",
       " 'Book_4_《矩阵力量》 | 鸢尾花书：从加减乘除到机器学习；上架！',\n",
       " 'Type-safe, K-sortable, globally unique identifier inspired by Stripe IDs']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c212d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url=[]\n",
    "start=0\n",
    "end=1\n",
    "try:\n",
    "    for page in range(start,end):   \n",
    "        url = driver.find_elements(By.XPATH, '//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "        for i in url:\n",
    "            repo_url.append(i.get_attribute('href'))\n",
    "except NoSuchElementException :\n",
    "        repo_url.append('No url')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb8aa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/PowerShell/PowerShell',\n",
       " 'https://github.com/WeMakeDevs/open-source-course',\n",
       " 'https://github.com/toeverything/AFFiNE',\n",
       " 'https://github.com/facebook/folly',\n",
       " 'https://github.com/ChaoningZhang/MobileSAM',\n",
       " 'https://github.com/imgly/background-removal-js',\n",
       " 'https://github.com/practical-tutorials/project-based-learning',\n",
       " 'https://github.com/wgwang/LLMs-In-China',\n",
       " 'https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving',\n",
       " 'https://github.com/ripienaar/free-for-dev',\n",
       " 'https://github.com/homanp/superagent',\n",
       " 'https://github.com/hiyouga/ChatGLM-Efficient-Tuning',\n",
       " 'https://github.com/EbookFoundation/free-programming-books',\n",
       " 'https://github.com/teslamotors/fleet-telemetry',\n",
       " 'https://github.com/labmlai/annotated_deep_learning_paper_implementations',\n",
       " 'https://github.com/huggingface/transformers',\n",
       " 'https://github.com/StanGirard/quivr',\n",
       " 'https://github.com/dotnet-architecture/eShopOnContainers',\n",
       " 'https://github.com/rust-lang/mdBook',\n",
       " 'https://github.com/LiLittleCat/awesome-free-chatgpt',\n",
       " 'https://github.com/geerlingguy/ansible-for-devops',\n",
       " 'https://github.com/phodal/aigc',\n",
       " 'https://github.com/PromtEngineer/localGPT',\n",
       " 'https://github.com/Visualize-ML/Book4_Power-of-Matrix',\n",
       " 'https://github.com/jetpack-io/typeid']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07bffc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Language=[]\n",
    "lan_tags=driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')\n",
    "for i in lan_tags[0:50]:\n",
    "    lan=i.text\n",
    "    Language.append(lan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2e23dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce9f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "Count=[]\n",
    "for i in repo_url[0:25]: \n",
    "    driver.get(i) \n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        count = driver.find_element(By.XPATH,'//div[@class=\"Layout-sidebar\"]/div/div[4]/div/h2/a/span') \n",
    "        Count.append(count.text) \n",
    "    except NoSuchElementException : \n",
    "        Count.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be997eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C#',\n",
       " 'TypeScript',\n",
       " 'C++',\n",
       " 'Jupyter Notebook',\n",
       " 'TypeScript',\n",
       " 'HTML',\n",
       " 'JavaScript',\n",
       " 'Python',\n",
       " 'Go',\n",
       " 'Jupyter Notebook',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'C#',\n",
       " 'Rust',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Rust',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Go']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66d0b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PowerShell /</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>435</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeMakeDevs /</td>\n",
       "      <td>There can be more than Notion and Miro. AFFiNE...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toeverything /</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>8</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook /</td>\n",
       "      <td>This is the official code for Faster Segment A...</td>\n",
       "      <td>-</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChaoningZhang /</td>\n",
       "      <td>Remove backgrounds from images directly in the...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>imgly /</td>\n",
       "      <td>Curated list of project-based tutorials</td>\n",
       "      <td>1</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>practical-tutorials /</td>\n",
       "      <td>中国大模型</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wgwang /</td>\n",
       "      <td>All you need for End-to-end Autonomous Driving</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OpenDriveLab /</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "      <td>-</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ripienaar /</td>\n",
       "      <td>🥷 Superagent - Build, deploy, and manage LLM-p...</td>\n",
       "      <td>-</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>homanp /</td>\n",
       "      <td>Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hiyouga /</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EbookFoundation /</td>\n",
       "      <td>🧑‍🏫 59 Implementations/tutorials of deep learn...</td>\n",
       "      <td>2,517</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>teslamotors /</td>\n",
       "      <td>🤗 Transformers: State-of-the-art Machine Learn...</td>\n",
       "      <td>-</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>labmlai /</td>\n",
       "      <td>🧠 Dump all your files into your private Genera...</td>\n",
       "      <td>21</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>huggingface /</td>\n",
       "      <td>Cross-platform .NET sample microservices and c...</td>\n",
       "      <td>79.3k</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>StanGirard /</td>\n",
       "      <td>Create book from markdown files. Like Gitbook ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dotnet-architecture /</td>\n",
       "      <td>🆓免费的 ChatGPT 镜像网站列表，持续更新。List of free ChatGPT ...</td>\n",
       "      <td>12</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rust-lang /</td>\n",
       "      <td>Ansible for DevOps examples.</td>\n",
       "      <td>275</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LiLittleCat /</td>\n",
       "      <td>《构筑大语言模型应用：应用开发与架构设计》一本关于 LLM 在真实世界应用的开源电子书，介绍...</td>\n",
       "      <td>18</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Repository title                             Repository description  \\\n",
       "0            PowerShell /                       PowerShell for every system!   \n",
       "1            WeMakeDevs /  There can be more than Notion and Miro. AFFiNE...   \n",
       "2          toeverything /  An open-source C++ library developed and used ...   \n",
       "3              facebook /  This is the official code for Faster Segment A...   \n",
       "4         ChaoningZhang /  Remove backgrounds from images directly in the...   \n",
       "5                 imgly /            Curated list of project-based tutorials   \n",
       "6   practical-tutorials /                                              中国大模型   \n",
       "7                wgwang /     All you need for End-to-end Autonomous Driving   \n",
       "8          OpenDriveLab /  A list of SaaS, PaaS and IaaS offerings that h...   \n",
       "9             ripienaar /  🥷 Superagent - Build, deploy, and manage LLM-p...   \n",
       "10               homanp /  Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效...   \n",
       "11              hiyouga /               📚 Freely available programming books   \n",
       "12      EbookFoundation /  🧑‍🏫 59 Implementations/tutorials of deep learn...   \n",
       "13          teslamotors /  🤗 Transformers: State-of-the-art Machine Learn...   \n",
       "14              labmlai /  🧠 Dump all your files into your private Genera...   \n",
       "15          huggingface /  Cross-platform .NET sample microservices and c...   \n",
       "16           StanGirard /  Create book from markdown files. Like Gitbook ...   \n",
       "17  dotnet-architecture /  🆓免费的 ChatGPT 镜像网站列表，持续更新。List of free ChatGPT ...   \n",
       "18            rust-lang /                       Ansible for DevOps examples.   \n",
       "19          LiLittleCat /  《构筑大语言模型应用：应用开发与架构设计》一本关于 LLM 在真实世界应用的开源电子书，介绍...   \n",
       "\n",
       "   Contributors count     Language used  \n",
       "0                 435                C#  \n",
       "1                   -        TypeScript  \n",
       "2                   8               C++  \n",
       "3                   -  Jupyter Notebook  \n",
       "4                   -        TypeScript  \n",
       "5                   1              HTML  \n",
       "6                   -        JavaScript  \n",
       "7                   -            Python  \n",
       "8                   -                Go  \n",
       "9                   -  Jupyter Notebook  \n",
       "10                  -            Python  \n",
       "11                  -        TypeScript  \n",
       "12              2,517                C#  \n",
       "13                  -              Rust  \n",
       "14                 21            Python  \n",
       "15              79.3k            Python  \n",
       "16                  -              Rust  \n",
       "17                 12            Python  \n",
       "18                275            Python  \n",
       "19                 18                Go  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df4=pd.DataFrame({'Repository title':Title[0:20],'Repository description':Description[0:20],'Contributors count':Count[0:20],'Language used':Language[0:20]})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc60a8",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a65608b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https:/www.billboard.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61c5432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chartclick=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[1]/div/div/div[2]/div/nav/ul/li[1]/a\")\n",
    "chartclick.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed702f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chartclick1=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a\")\n",
    "chartclick1.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45acb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song=[]\n",
    "Artist=[]\n",
    "last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "weeks_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4783568",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in song_tags[0:100]:\n",
    "    song=i.text\n",
    "    Song.append(song)\n",
    "Art_tags=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "for i in Art_tags[0:100]:\n",
    "    Art=i.text\n",
    "    Artist.append(Art)\n",
    "last_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[4]/span')\n",
    "for i in last_tags[0:100]:\n",
    "    last=i.text\n",
    "    last_week_rank.append(last)\n",
    "Peak_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak_tags[0:100]:\n",
    "    Peak=i.text\n",
    "    Peak_rank.append(Peak)\n",
    "week_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[6]/span')\n",
    "for i in week_tags[0:100]:\n",
    "    week=i.text\n",
    "    weeks_board.append(week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f63684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "256f0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song1=[]\n",
    "Artist1=[]\n",
    "last_week_rank1=[]\n",
    "Peak_rank1=[]\n",
    "weeks_board1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1231c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "song1_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li/h3')\n",
    "for i in song1_tags[0:100]:\n",
    "    song1=i.text\n",
    "    Song1.append(song1)\n",
    "Art1_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/span')\n",
    "for i in Art1_tags[0:100]:\n",
    "    Art1=i.text\n",
    "    Artist1.append(Art1)\n",
    "last1_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]/span')\n",
    "for i in last1_tags[0:100]:\n",
    "    last1=i.text\n",
    "    last_week_rank1.append(last1)\n",
    "Peak1_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "for i in Peak1_tags[0:100]:\n",
    "    Peak1=i.text\n",
    "    Peak_rank1.append(Peak1)\n",
    "week1_tags=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]/span')\n",
    "for i in week1_tags[0:100]:\n",
    "    week1=i.text\n",
    "    weeks_board1.append(week1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0e7e5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Artist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b0c4e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Angel, Pt. 1</td>\n",
       "      <td>-</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Girl In Mine</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Moonlight</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Classy 101</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bluffin</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song name Last week rank Peak rank Weeks on board\n",
       "0     Last Night              1         1             21\n",
       "1       Fast Car              3         2             13\n",
       "2      Calm Down              4         3             42\n",
       "3        Flowers              2         1             23\n",
       "4    All My Life              5         2              6\n",
       "..           ...            ...       ...            ...\n",
       "95  Angel, Pt. 1              -        65              2\n",
       "96  Girl In Mine              -        97              1\n",
       "97     Moonlight             90        80             11\n",
       "98    Classy 101              -        99              1\n",
       "99       Bluffin              -       100              1\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df5=pd.DataFrame({'Song name':Song1[0:100],'Last week rank':last_week_rank1[0:100],'Peak rank':Peak_rank1[0:100],'Weeks on board':weeks_board1[0:100]})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd929a8",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0dc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1007be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Article=[]\n",
    "Author=[]\n",
    "uploaded=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d172b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Art_tags=driver.find_elements(By.XPATH,'//h2[@class=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"]')\n",
    "for i in Art_tags[0:100]:\n",
    "    Art=i.text\n",
    "    Article.append(Art)\n",
    "\n",
    "Auth_tags=driver.find_elements(By.XPATH,'//p[@class=\"sc-1thf9ly-0 sc-1thf9ly-1 iwnLUR fXmEge\"]/span[1]')\n",
    "for i in Auth_tags[0:100]:\n",
    "    Auth=i.text\n",
    "    Author.append(Auth)\n",
    "\n",
    "uplo_tags=driver.find_elements(By.XPATH,'//p[@class=\"sc-1thf9ly-0 sc-1thf9ly-1 iwnLUR fXmEge\"]/span[2]')\n",
    "for i in uplo_tags[0:100]:\n",
    "    uplo=i.text\n",
    "    uploaded.append(uplo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0739dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Editor</th>\n",
       "      <th>Upload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Article  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                               Editor          Upload  \n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021  \n",
       "1                                          Tim Miller   February 2019  \n",
       "2                                   Margaret A. Boden     August 1998  \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015  \n",
       "4                      Ilaria Tiddi, Stefan Schlobach    January 2022  \n",
       "5                      Henry Prakken, Giovanni Sartor    October 2015  \n",
       "6     Richard S. Sutton, Doina Precup, Satinder Singh     August 1999  \n",
       "7           Kjersti Aas, Martin Jullum, Anders Løland  September 2021  \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021  \n",
       "9                       Saurabh Arora, Prashant Doshi     August 2021  \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021  \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023  \n",
       "12   Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz   November 2021  \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023  \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021  \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020  \n",
       "16                         Ron Kohavi, George H. John   December 1997  \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017  \n",
       "18    Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz       June 2021  \n",
       "19                             Luigia Carlucci Aiello       June 2016  \n",
       "20             Patrick Lin, Keith Abney, George Bekey      April 2011  \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023  \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998  \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df6=pd.DataFrame({'Article':Article,'Editor':Author,'Upload':uploaded})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8582b6",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d337d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1aef7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Ratings=[]\n",
    "Vote=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dbecc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/h3/span[2]')\n",
    "for i in span_tags[0:100]:\n",
    "    span=i.text\n",
    "    Year_span.append(span)\n",
    "Gen_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p/span[5]')\n",
    "for i in Gen_tags[0:100]:\n",
    "    Gen=i.text\n",
    "    Genre.append(Gen)\n",
    "\n",
    "vote_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p[4]/span[2]')\n",
    "for i in vote_tags[0:100]:\n",
    "    vote=i.text\n",
    "    Vote.append(vote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4733cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings=[]\n",
    "Rate_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/div/div/span[2]')\n",
    "for i in Rate_tags[0:100]:\n",
    "    Rate=i.text\n",
    "    Ratings.append(Rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "36c90566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f29bce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_url=[]\n",
    "start=0\n",
    "end=1\n",
    "try:\n",
    "    for page in range(start,end):   \n",
    "        url = driver.find_elements(By.XPATH, '//h3[@class=\"lister-item-header\"]/a')\n",
    "        for i in url:\n",
    "            show_url.append(i.get_attribute('href'))\n",
    "except NoSuchElementException :\n",
    "        repo_url.append('No url')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55ba81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Count=[]\n",
    "for i in show_url[0:100]: \n",
    "    driver.get(i) \n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        count = driver.find_element(By.XPATH,'//span[@class=\"sc-afe43def-1 fDTGTb\"]') \n",
    "        Count.append(count.text) \n",
    "    except NoSuchElementException : \n",
    "        Count.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2f00189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d92a4d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,174,821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,252,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,033,004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303,732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>208,627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>7</td>\n",
       "      <td>43,417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>8.6</td>\n",
       "      <td>260,438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Ratings      Votes  \n",
       "0      9.2  2,174,821  \n",
       "1      8.7  1,252,525  \n",
       "2      8.1  1,033,004  \n",
       "3      7.5    303,732  \n",
       "4      7.6    262,868  \n",
       "..     ...        ...  \n",
       "95     7.4     51,990  \n",
       "96     7.8     64,015  \n",
       "97     8.1    208,627  \n",
       "98       7     43,417  \n",
       "99     8.6    260,438  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df6=pd.DataFrame({'Name':Count[0:100],'Year Span':Year_span[0:100],'Genre':Genre[0:100],'Ratings':Ratings[0:100],'Votes':Vote[0:100]})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eb785",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8460a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f61585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetclick=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "datasetclick.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e197a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url=[]\n",
    "start=0\n",
    "end=5\n",
    "try:\n",
    "    for page in range(start,end):   \n",
    "        url = driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "        for i in url:\n",
    "            data_url.append(i.get_attribute('href'))\n",
    "except NoSuchElementException :\n",
    "        data_url.append('No url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144beb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/19/car+evaluation',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/73/mushroom',\n",
       " 'https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/19/car+evaluation',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/73/mushroom',\n",
       " 'https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/19/car+evaluation',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/73/mushroom',\n",
       " 'https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/19/car+evaluation',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/73/mushroom',\n",
       " 'https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/19/car+evaluation',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/73/mushroom']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80727459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f653466",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a89869",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_url: \n",
    "    driver.get(i) \n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        data = driver.find_element(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]') \n",
    "        Dataset_name.append(data.text) \n",
    "    except NoSuchElementException : \n",
    "        Dataset_name.append('-')\n",
    "        \n",
    "    try:\n",
    "        dataco = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div/p') \n",
    "        Data_type.append(dataco.text) \n",
    "    except NoSuchElementException : \n",
    "        Data_type.append('-')\n",
    "        \n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[3]/p') \n",
    "        Task.append(task.text) \n",
    "    except NoSuchElementException : \n",
    "        Task.append('-')\n",
    "        \n",
    "    try:\n",
    "        Attri = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[4]/p') \n",
    "        Attribute_type.append(Attri.text) \n",
    "    except NoSuchElementException : \n",
    "        Attribute_type.append('-')\n",
    "        \n",
    "    try:\n",
    "        noofi = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[5]/p') \n",
    "        No_of_instances.append(noofi.text) \n",
    "    except NoSuchElementException : \n",
    "        No_of_instances.append('-')\n",
    "        \n",
    "    try:\n",
    "        noofa = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[6]/p') \n",
    "        No_of_attribute.append(noofa.text) \n",
    "    except NoSuchElementException : \n",
    "        No_of_attribute.append('-')\n",
    "    \n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,'//h2[@class=\"text-primary-content\"]') \n",
    "        Year.append(year.text) \n",
    "    except NoSuchElementException : \n",
    "        Year.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19fbfeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Donated on 6/30/1988',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 4/30/1996',\n",
       " 'Donated on 9/13/2020',\n",
       " '-',\n",
       " 'Donated on 10/5/2019',\n",
       " 'Donated on 6/30/1991',\n",
       " 'Donated on 5/31/1997',\n",
       " 'Donated on 10/31/1995',\n",
       " 'Donated on 4/26/1987',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 4/30/1996',\n",
       " 'Donated on 9/13/2020',\n",
       " '-',\n",
       " 'Donated on 10/5/2019',\n",
       " 'Donated on 6/30/1991',\n",
       " 'Donated on 5/31/1997',\n",
       " 'Donated on 10/31/1995',\n",
       " 'Donated on 4/26/1987',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 4/30/1996',\n",
       " 'Donated on 9/13/2020',\n",
       " '-',\n",
       " 'Donated on 10/5/2019',\n",
       " 'Donated on 6/30/1991',\n",
       " 'Donated on 5/31/1997',\n",
       " 'Donated on 10/31/1995',\n",
       " 'Donated on 4/26/1987',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 4/30/1996',\n",
       " 'Donated on 9/13/2020',\n",
       " '-',\n",
       " 'Donated on 10/5/2019',\n",
       " 'Donated on 6/30/1991',\n",
       " 'Donated on 5/31/1997',\n",
       " 'Donated on 10/31/1995',\n",
       " 'Donated on 4/26/1987',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 4/30/1996',\n",
       " 'Donated on 9/13/2020',\n",
       " '-',\n",
       " 'Donated on 10/5/2019',\n",
       " 'Donated on 6/30/1991',\n",
       " 'Donated on 5/31/1997',\n",
       " 'Donated on 10/31/1995',\n",
       " 'Donated on 4/26/1987']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ed5f2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1988', '1988', '1996', '2020', '-', '2019', '1991', '1997', '1995', '1987', '1988', '1988', '1996', '2020', '-', '2019', '1991', '1997', '1995', '1987', '1988', '1988', '1996', '2020', '-', '2019', '1991', '1997', '1995', '1987', '1988', '1988', '1996', '2020', '-', '2019', '1991', '1997', '1995', '1987', '1988', '1988', '1996', '2020', '-', '2019', '1991', '1997', '1995', '1987']\n"
     ]
    }
   ],
   "source": [
    "years = []\n",
    "for item in Year:\n",
    "        date = item.split(' ')[-1]\n",
    "        year = date.split('/')[-1]\n",
    "        years.append(year)\n",
    "\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2e7d014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3969ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8124</td>\n",
       "      <td>22</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8124</td>\n",
       "      <td>22</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8124</td>\n",
       "      <td>22</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8124</td>\n",
       "      <td>22</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8124</td>\n",
       "      <td>22</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Dataset name                  Data type  \\\n",
       "0                                   Iris               Multivariate   \n",
       "1                          Heart Disease               Multivariate   \n",
       "2                                  Adult               Multivariate   \n",
       "3                       Dry Bean Dataset               Multivariate   \n",
       "4                               Diabetes  Multivariate, Time-Series   \n",
       "5             Rice (Cammeo and Osmancik)               Multivariate   \n",
       "6                                   Wine               Multivariate   \n",
       "7                         Car Evaluation               Multivariate   \n",
       "8   Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "9                               Mushroom               Multivariate   \n",
       "10                                  Iris               Multivariate   \n",
       "11                         Heart Disease               Multivariate   \n",
       "12                                 Adult               Multivariate   \n",
       "13                      Dry Bean Dataset               Multivariate   \n",
       "14                              Diabetes  Multivariate, Time-Series   \n",
       "15            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "16                                  Wine               Multivariate   \n",
       "17                        Car Evaluation               Multivariate   \n",
       "18  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "19                              Mushroom               Multivariate   \n",
       "20                                  Iris               Multivariate   \n",
       "21                         Heart Disease               Multivariate   \n",
       "22                                 Adult               Multivariate   \n",
       "23                      Dry Bean Dataset               Multivariate   \n",
       "24                              Diabetes  Multivariate, Time-Series   \n",
       "25            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "26                                  Wine               Multivariate   \n",
       "27                        Car Evaluation               Multivariate   \n",
       "28  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "29                              Mushroom               Multivariate   \n",
       "30                                  Iris               Multivariate   \n",
       "31                         Heart Disease               Multivariate   \n",
       "32                                 Adult               Multivariate   \n",
       "33                      Dry Bean Dataset               Multivariate   \n",
       "34                              Diabetes  Multivariate, Time-Series   \n",
       "35            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "36                                  Wine               Multivariate   \n",
       "37                        Car Evaluation               Multivariate   \n",
       "38  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "39                              Mushroom               Multivariate   \n",
       "40                                  Iris               Multivariate   \n",
       "41                         Heart Disease               Multivariate   \n",
       "42                                 Adult               Multivariate   \n",
       "43                      Dry Bean Dataset               Multivariate   \n",
       "44                              Diabetes  Multivariate, Time-Series   \n",
       "45            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "46                                  Wine               Multivariate   \n",
       "47                        Car Evaluation               Multivariate   \n",
       "48  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "49                              Mushroom               Multivariate   \n",
       "\n",
       "              Task              Attribute type No of instances  \\\n",
       "0   Classification                        Real             150   \n",
       "1   Classification  Categorical, Integer, Real             303   \n",
       "2   Classification        Categorical, Integer           48842   \n",
       "3   Classification               Integer, Real           13611   \n",
       "4                -        Categorical, Integer               -   \n",
       "5   Classification                        Real            3810   \n",
       "6   Classification               Integer, Real             178   \n",
       "7   Classification                 Categorical            1728   \n",
       "8   Classification                        Real             569   \n",
       "9   Classification                 Categorical            8124   \n",
       "10  Classification                        Real             150   \n",
       "11  Classification  Categorical, Integer, Real             303   \n",
       "12  Classification        Categorical, Integer           48842   \n",
       "13  Classification               Integer, Real           13611   \n",
       "14               -        Categorical, Integer               -   \n",
       "15  Classification                        Real            3810   \n",
       "16  Classification               Integer, Real             178   \n",
       "17  Classification                 Categorical            1728   \n",
       "18  Classification                        Real             569   \n",
       "19  Classification                 Categorical            8124   \n",
       "20  Classification                        Real             150   \n",
       "21  Classification  Categorical, Integer, Real             303   \n",
       "22  Classification        Categorical, Integer           48842   \n",
       "23  Classification               Integer, Real           13611   \n",
       "24               -        Categorical, Integer               -   \n",
       "25  Classification                        Real            3810   \n",
       "26  Classification               Integer, Real             178   \n",
       "27  Classification                 Categorical            1728   \n",
       "28  Classification                        Real             569   \n",
       "29  Classification                 Categorical            8124   \n",
       "30  Classification                        Real             150   \n",
       "31  Classification  Categorical, Integer, Real             303   \n",
       "32  Classification        Categorical, Integer           48842   \n",
       "33  Classification               Integer, Real           13611   \n",
       "34               -        Categorical, Integer               -   \n",
       "35  Classification                        Real            3810   \n",
       "36  Classification               Integer, Real             178   \n",
       "37  Classification                 Categorical            1728   \n",
       "38  Classification                        Real             569   \n",
       "39  Classification                 Categorical            8124   \n",
       "40  Classification                        Real             150   \n",
       "41  Classification  Categorical, Integer, Real             303   \n",
       "42  Classification        Categorical, Integer           48842   \n",
       "43  Classification               Integer, Real           13611   \n",
       "44               -        Categorical, Integer               -   \n",
       "45  Classification                        Real            3810   \n",
       "46  Classification               Integer, Real             178   \n",
       "47  Classification                 Categorical            1728   \n",
       "48  Classification                        Real             569   \n",
       "49  Classification                 Categorical            8124   \n",
       "\n",
       "   No of attribute  Year  \n",
       "0                4  1988  \n",
       "1               13  1988  \n",
       "2               14  1996  \n",
       "3               17  2020  \n",
       "4               20     -  \n",
       "5                8  2019  \n",
       "6               13  1991  \n",
       "7                6  1997  \n",
       "8               30  1995  \n",
       "9               22  1987  \n",
       "10               4  1988  \n",
       "11              13  1988  \n",
       "12              14  1996  \n",
       "13              17  2020  \n",
       "14              20     -  \n",
       "15               8  2019  \n",
       "16              13  1991  \n",
       "17               6  1997  \n",
       "18              30  1995  \n",
       "19              22  1987  \n",
       "20               4  1988  \n",
       "21              13  1988  \n",
       "22              14  1996  \n",
       "23              17  2020  \n",
       "24              20     -  \n",
       "25               8  2019  \n",
       "26              13  1991  \n",
       "27               6  1997  \n",
       "28              30  1995  \n",
       "29              22  1987  \n",
       "30               4  1988  \n",
       "31              13  1988  \n",
       "32              14  1996  \n",
       "33              17  2020  \n",
       "34              20     -  \n",
       "35               8  2019  \n",
       "36              13  1991  \n",
       "37               6  1997  \n",
       "38              30  1995  \n",
       "39              22  1987  \n",
       "40               4  1988  \n",
       "41              13  1988  \n",
       "42              14  1996  \n",
       "43              17  2020  \n",
       "44              20     -  \n",
       "45               8  2019  \n",
       "46              13  1991  \n",
       "47               6  1997  \n",
       "48              30  1995  \n",
       "49              22  1987  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df8=pd.DataFrame({'Dataset name':Dataset_name,'Data type':Data_type,'Task':Task,'Attribute type':Attribute_type,'No of instances':No_of_instances,'No of attribute':No_of_attribute,'Year':years})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f6443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3ce85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68847258",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd77b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1cad003",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input\")\n",
    "designation.send_keys('Data Science')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a7b5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[6]\")\n",
    "Search.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bfbee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills=[]\n",
    "Location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d88a2dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a3f5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in pos_tags[0:20]:\n",
    "    pos=i.text\n",
    "    Designation.append(pos)\n",
    "    \n",
    "com_tags=driver.find_elements(By.XPATH,'//div[@class=\"companyInfo subheading\"]/a[1]')\n",
    "for i in com_tags[0:20]:\n",
    "    com=i.text\n",
    "    Company.append(com)\n",
    "\n",
    "skill_tags=driver.find_elements(By.XPATH,'//ul[@class=\"tags has-description\"]')\n",
    "for i in skill_tags[0:20]:\n",
    "    skill=i.text\n",
    "    Skills.append(skill)\n",
    "    \n",
    "loc_tags=driver.find_elements(By.XPATH,'//article[@class=\"jobTuple\"]/div/ul/li[3]/span')\n",
    "for i in loc_tags[0:20]:\n",
    "    loc=i.text\n",
    "    Location.append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e89596b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Director - Data Science</td>\n",
       "      <td>Credgenics</td>\n",
       "      <td>Data Engineering\\ndata science\\nData Analytics...</td>\n",
       "      <td>Noida, Uttar Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Product Manager (Data Science, AI/ML)</td>\n",
       "      <td>Blue Yonder</td>\n",
       "      <td>SR\\nMarketing\\nData Science\\nAnalytical\\nManag...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Product Manager (Data Science/AI/ML)</td>\n",
       "      <td>Blue Yonder</td>\n",
       "      <td>Data Science\\nproduct manager\\nMachine\\nScienc...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr Analyst - Data Science and Analytics</td>\n",
       "      <td>Transunion</td>\n",
       "      <td>Analytics\\nFinance\\nBusiness intelligence\\nQua...</td>\n",
       "      <td>Pune, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Arbeit Associates</td>\n",
       "      <td>SQL\\nPython\\nData Science\\nData analytics\\nTab...</td>\n",
       "      <td>Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cluster Manager - Payments - Data Science/Seni...</td>\n",
       "      <td>Bajaj Finserv Ltd.</td>\n",
       "      <td>Python\\nArchitecture\\nData management\\nCluster...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L&amp;D Trainer - Python &amp; Data Science/Data Analy...</td>\n",
       "      <td>AVE-Promagne Business Solutions</td>\n",
       "      <td>Python\\nMachine\\nScience\\nDevelopment\\nMachine...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manager Data Science</td>\n",
       "      <td>Mondelez</td>\n",
       "      <td>SAP\\nScience\\nRecognition\\nDesign patterns\\nDa...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead - Data Science - Financial Services</td>\n",
       "      <td>Dimensions HRD Consultants</td>\n",
       "      <td>Data Science\\nFinancial services\\nScience\\nDat...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Head - Data Science &amp; Analytics - Bank</td>\n",
       "      <td>Dimensions HRD Consultants</td>\n",
       "      <td>Data Analytics\\nData Science\\nScience\\nData mo...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Engineer II- Data Science &amp; Analytics</td>\n",
       "      <td>Raytheon Technologies</td>\n",
       "      <td>Data Science\\nstatistical modeling\\nmachine le...</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manager/Senior Manager - Data Science</td>\n",
       "      <td>Axtria India</td>\n",
       "      <td>Data Science\\nNatural language processing\\nDat...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Analyst, Data Science</td>\n",
       "      <td>DUN BRADSTREET INFORMATION SERVICES INDIA PRIV...</td>\n",
       "      <td>Analysis\\nAnalytical\\nData Science\\nData analy...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science Manager (NLP) / EMBIZ</td>\n",
       "      <td>Tredence</td>\n",
       "      <td>Consulting\\nLanguages\\nManagement\\nAnalytical\\...</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AI/ML Developer - Python Programming and Data ...</td>\n",
       "      <td>Freestone Infotech Private Limited</td>\n",
       "      <td>python\\ndata science\\nTensorflow\\nFramework\\nD...</td>\n",
       "      <td>Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Head- Product Data Science</td>\n",
       "      <td>Olive Green Consulting</td>\n",
       "      <td>data science\\nbanking domain\\nPython\\nScience\\...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sr Programmer - Python / Data Science Developer</td>\n",
       "      <td>Ajanta Pharma</td>\n",
       "      <td>Data Modeling\\nPython\\nStatistics\\nData Scienc...</td>\n",
       "      <td>Mumbai, Maharashtra, Mumbai Suburban, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Science Analytics Sr Analyst - Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Science\\nCloud\\nInsights\\nSR\\nBusiness In...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Manager Data Science</td>\n",
       "      <td>Mondelez</td>\n",
       "      <td>Pattern recognition\\nSAP\\nData Science\\nAnalyt...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Global Practice Lead - Data Science</td>\n",
       "      <td>Teradata</td>\n",
       "      <td>Data Science\\nWarehouse\\nAnalytics\\nData\\nGlob...</td>\n",
       "      <td>Hybrid - Hyderabad/ Secunderabad, Telangana, P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Designation  \\\n",
       "0                             Director - Data Science   \n",
       "1           Sr. Product Manager (Data Science, AI/ML)   \n",
       "2             Sr Product Manager (Data Science/AI/ML)   \n",
       "3             Sr Analyst - Data Science and Analytics   \n",
       "4                               Data Science Engineer   \n",
       "5   Cluster Manager - Payments - Data Science/Seni...   \n",
       "6   L&D Trainer - Python & Data Science/Data Analy...   \n",
       "7                                Manager Data Science   \n",
       "8            Lead - Data Science - Financial Services   \n",
       "9              Head - Data Science & Analytics - Bank   \n",
       "10              Engineer II- Data Science & Analytics   \n",
       "11              Manager/Senior Manager - Data Science   \n",
       "12                       Senior Analyst, Data Science   \n",
       "13                 Data Science Manager (NLP) / EMBIZ   \n",
       "14  AI/ML Developer - Python Programming and Data ...   \n",
       "15                         Head- Product Data Science   \n",
       "16    Sr Programmer - Python / Data Science Developer   \n",
       "17   Data Science Analytics Sr Analyst - Data Science   \n",
       "18                               Manager Data Science   \n",
       "19                Global Practice Lead - Data Science   \n",
       "\n",
       "                                              Company  \\\n",
       "0                                          Credgenics   \n",
       "1                                         Blue Yonder   \n",
       "2                                         Blue Yonder   \n",
       "3                                          Transunion   \n",
       "4                                   Arbeit Associates   \n",
       "5                                  Bajaj Finserv Ltd.   \n",
       "6                     AVE-Promagne Business Solutions   \n",
       "7                                            Mondelez   \n",
       "8                          Dimensions HRD Consultants   \n",
       "9                          Dimensions HRD Consultants   \n",
       "10                              Raytheon Technologies   \n",
       "11                                       Axtria India   \n",
       "12  DUN BRADSTREET INFORMATION SERVICES INDIA PRIV...   \n",
       "13                                           Tredence   \n",
       "14                 Freestone Infotech Private Limited   \n",
       "15                             Olive Green Consulting   \n",
       "16                                      Ajanta Pharma   \n",
       "17                                          Accenture   \n",
       "18                                           Mondelez   \n",
       "19                                           Teradata   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   Data Engineering\\ndata science\\nData Analytics...   \n",
       "1   SR\\nMarketing\\nData Science\\nAnalytical\\nManag...   \n",
       "2   Data Science\\nproduct manager\\nMachine\\nScienc...   \n",
       "3   Analytics\\nFinance\\nBusiness intelligence\\nQua...   \n",
       "4   SQL\\nPython\\nData Science\\nData analytics\\nTab...   \n",
       "5   Python\\nArchitecture\\nData management\\nCluster...   \n",
       "6   Python\\nMachine\\nScience\\nDevelopment\\nMachine...   \n",
       "7   SAP\\nScience\\nRecognition\\nDesign patterns\\nDa...   \n",
       "8   Data Science\\nFinancial services\\nScience\\nDat...   \n",
       "9   Data Analytics\\nData Science\\nScience\\nData mo...   \n",
       "10  Data Science\\nstatistical modeling\\nmachine le...   \n",
       "11  Data Science\\nNatural language processing\\nDat...   \n",
       "12  Analysis\\nAnalytical\\nData Science\\nData analy...   \n",
       "13  Consulting\\nLanguages\\nManagement\\nAnalytical\\...   \n",
       "14  python\\ndata science\\nTensorflow\\nFramework\\nD...   \n",
       "15  data science\\nbanking domain\\nPython\\nScience\\...   \n",
       "16  Data Modeling\\nPython\\nStatistics\\nData Scienc...   \n",
       "17  Data Science\\nCloud\\nInsights\\nSR\\nBusiness In...   \n",
       "18  Pattern recognition\\nSAP\\nData Science\\nAnalyt...   \n",
       "19  Data Science\\nWarehouse\\nAnalytics\\nData\\nGlob...   \n",
       "\n",
       "                                             Location  \n",
       "0                                Noida, Uttar Pradesh  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                                              Remote  \n",
       "3                                       Pune, Chennai  \n",
       "4   Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...  \n",
       "5                                                Pune  \n",
       "6   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  \n",
       "7                                              Mumbai  \n",
       "8                                    Gurgaon/Gurugram  \n",
       "9                                    Gurgaon/Gurugram  \n",
       "10  Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...  \n",
       "11  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...  \n",
       "12                             Hyderabad/Secunderabad  \n",
       "13  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...  \n",
       "14                                 Mumbai (All Areas)  \n",
       "15                                Bangalore/Bengaluru  \n",
       "16  Mumbai, Maharashtra, Mumbai Suburban, Maharashtra  \n",
       "17                                             Mumbai  \n",
       "18                                             Mumbai  \n",
       "19  Hybrid - Hyderabad/ Secunderabad, Telangana, P...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df9_test=pd.DataFrame({'Designation':Designation,'Company':Company,'Skills':Skills,'Location':Location})\n",
    "df9_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a162f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = [s.replace('\\n', ',') for s in Skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d3f6602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Director - Data Science</td>\n",
       "      <td>Credgenics</td>\n",
       "      <td>Data Engineering,data science,Data Analytics,M...</td>\n",
       "      <td>Noida, Uttar Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Product Manager (Data Science, AI/ML)</td>\n",
       "      <td>Blue Yonder</td>\n",
       "      <td>SR,Marketing,Data Science,Analytical,Managemen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Product Manager (Data Science/AI/ML)</td>\n",
       "      <td>Blue Yonder</td>\n",
       "      <td>Data Science,product manager,Machine,Science,A...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr Analyst - Data Science and Analytics</td>\n",
       "      <td>Transunion</td>\n",
       "      <td>Analytics,Finance,Business intelligence,Qualit...</td>\n",
       "      <td>Pune, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Arbeit Associates</td>\n",
       "      <td>SQL,Python,Data Science,Data analytics,Tableau...</td>\n",
       "      <td>Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cluster Manager - Payments - Data Science/Seni...</td>\n",
       "      <td>Bajaj Finserv Ltd.</td>\n",
       "      <td>Python,Architecture,Data management,Cluster Ma...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L&amp;D Trainer - Python &amp; Data Science/Data Analy...</td>\n",
       "      <td>AVE-Promagne Business Solutions</td>\n",
       "      <td>Python,Machine,Science,Development,Machine lea...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manager Data Science</td>\n",
       "      <td>Mondelez</td>\n",
       "      <td>SAP,Science,Recognition,Design patterns,Data S...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead - Data Science - Financial Services</td>\n",
       "      <td>Dimensions HRD Consultants</td>\n",
       "      <td>Data Science,Financial services,Science,Data m...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Head - Data Science &amp; Analytics - Bank</td>\n",
       "      <td>Dimensions HRD Consultants</td>\n",
       "      <td>Data Analytics,Data Science,Science,Data model...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Engineer II- Data Science &amp; Analytics</td>\n",
       "      <td>Raytheon Technologies</td>\n",
       "      <td>Data Science,statistical modeling,machine lear...</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manager/Senior Manager - Data Science</td>\n",
       "      <td>Axtria India</td>\n",
       "      <td>Data Science,Natural language processing,Data ...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Analyst, Data Science</td>\n",
       "      <td>DUN BRADSTREET INFORMATION SERVICES INDIA PRIV...</td>\n",
       "      <td>Analysis,Analytical,Data Science,Data analysis...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science Manager (NLP) / EMBIZ</td>\n",
       "      <td>Tredence</td>\n",
       "      <td>Consulting,Languages,Management,Analytical,Dat...</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AI/ML Developer - Python Programming and Data ...</td>\n",
       "      <td>Freestone Infotech Private Limited</td>\n",
       "      <td>python,data science,Tensorflow,Framework,Deep ...</td>\n",
       "      <td>Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Head- Product Data Science</td>\n",
       "      <td>Olive Green Consulting</td>\n",
       "      <td>data science,banking domain,Python,Science,RDB...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sr Programmer - Python / Data Science Developer</td>\n",
       "      <td>Ajanta Pharma</td>\n",
       "      <td>Data Modeling,Python,Statistics,Data Science,E...</td>\n",
       "      <td>Mumbai, Maharashtra, Mumbai Suburban, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Science Analytics Sr Analyst - Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Science,Cloud,Insights,SR,Business Insigh...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Manager Data Science</td>\n",
       "      <td>Mondelez</td>\n",
       "      <td>Pattern recognition,SAP,Data Science,Analytics...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Global Practice Lead - Data Science</td>\n",
       "      <td>Teradata</td>\n",
       "      <td>Data Science,Warehouse,Analytics,Data,Global,D...</td>\n",
       "      <td>Hybrid - Hyderabad/ Secunderabad, Telangana, P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Designation  \\\n",
       "0                             Director - Data Science   \n",
       "1           Sr. Product Manager (Data Science, AI/ML)   \n",
       "2             Sr Product Manager (Data Science/AI/ML)   \n",
       "3             Sr Analyst - Data Science and Analytics   \n",
       "4                               Data Science Engineer   \n",
       "5   Cluster Manager - Payments - Data Science/Seni...   \n",
       "6   L&D Trainer - Python & Data Science/Data Analy...   \n",
       "7                                Manager Data Science   \n",
       "8            Lead - Data Science - Financial Services   \n",
       "9              Head - Data Science & Analytics - Bank   \n",
       "10              Engineer II- Data Science & Analytics   \n",
       "11              Manager/Senior Manager - Data Science   \n",
       "12                       Senior Analyst, Data Science   \n",
       "13                 Data Science Manager (NLP) / EMBIZ   \n",
       "14  AI/ML Developer - Python Programming and Data ...   \n",
       "15                         Head- Product Data Science   \n",
       "16    Sr Programmer - Python / Data Science Developer   \n",
       "17   Data Science Analytics Sr Analyst - Data Science   \n",
       "18                               Manager Data Science   \n",
       "19                Global Practice Lead - Data Science   \n",
       "\n",
       "                                              Company  \\\n",
       "0                                          Credgenics   \n",
       "1                                         Blue Yonder   \n",
       "2                                         Blue Yonder   \n",
       "3                                          Transunion   \n",
       "4                                   Arbeit Associates   \n",
       "5                                  Bajaj Finserv Ltd.   \n",
       "6                     AVE-Promagne Business Solutions   \n",
       "7                                            Mondelez   \n",
       "8                          Dimensions HRD Consultants   \n",
       "9                          Dimensions HRD Consultants   \n",
       "10                              Raytheon Technologies   \n",
       "11                                       Axtria India   \n",
       "12  DUN BRADSTREET INFORMATION SERVICES INDIA PRIV...   \n",
       "13                                           Tredence   \n",
       "14                 Freestone Infotech Private Limited   \n",
       "15                             Olive Green Consulting   \n",
       "16                                      Ajanta Pharma   \n",
       "17                                          Accenture   \n",
       "18                                           Mondelez   \n",
       "19                                           Teradata   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   Data Engineering,data science,Data Analytics,M...   \n",
       "1   SR,Marketing,Data Science,Analytical,Managemen...   \n",
       "2   Data Science,product manager,Machine,Science,A...   \n",
       "3   Analytics,Finance,Business intelligence,Qualit...   \n",
       "4   SQL,Python,Data Science,Data analytics,Tableau...   \n",
       "5   Python,Architecture,Data management,Cluster Ma...   \n",
       "6   Python,Machine,Science,Development,Machine lea...   \n",
       "7   SAP,Science,Recognition,Design patterns,Data S...   \n",
       "8   Data Science,Financial services,Science,Data m...   \n",
       "9   Data Analytics,Data Science,Science,Data model...   \n",
       "10  Data Science,statistical modeling,machine lear...   \n",
       "11  Data Science,Natural language processing,Data ...   \n",
       "12  Analysis,Analytical,Data Science,Data analysis...   \n",
       "13  Consulting,Languages,Management,Analytical,Dat...   \n",
       "14  python,data science,Tensorflow,Framework,Deep ...   \n",
       "15  data science,banking domain,Python,Science,RDB...   \n",
       "16  Data Modeling,Python,Statistics,Data Science,E...   \n",
       "17  Data Science,Cloud,Insights,SR,Business Insigh...   \n",
       "18  Pattern recognition,SAP,Data Science,Analytics...   \n",
       "19  Data Science,Warehouse,Analytics,Data,Global,D...   \n",
       "\n",
       "                                             Location  \n",
       "0                                Noida, Uttar Pradesh  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                                              Remote  \n",
       "3                                       Pune, Chennai  \n",
       "4   Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...  \n",
       "5                                                Pune  \n",
       "6   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  \n",
       "7                                              Mumbai  \n",
       "8                                    Gurgaon/Gurugram  \n",
       "9                                    Gurgaon/Gurugram  \n",
       "10  Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...  \n",
       "11  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...  \n",
       "12                             Hyderabad/Secunderabad  \n",
       "13  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...  \n",
       "14                                 Mumbai (All Areas)  \n",
       "15                                Bangalore/Bengaluru  \n",
       "16  Mumbai, Maharashtra, Mumbai Suburban, Maharashtra  \n",
       "17                                             Mumbai  \n",
       "18                                             Mumbai  \n",
       "19  Hybrid - Hyderabad/ Secunderabad, Telangana, P...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9=pd.DataFrame({'Designation':Designation,'Company':Company,'Skills':skills,'Location':Location})\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150f528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0e930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fe90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c950f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4449e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
